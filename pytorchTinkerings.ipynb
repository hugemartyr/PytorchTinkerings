{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyMq/B3jqudZlAlLZeA1zktK",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/hugemartyr/PytorchTinkerings/blob/main/pytorchTinkerings.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vUYjwNIUHtmT",
        "outputId": "e9b1d0a8-385a-415b-8173-df558805abb3"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "7"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ],
      "source": [
        "import torch\n",
        "torch.__version__\n",
        "scalar= torch.tensor(7)\n",
        "\n",
        "scalar.item()\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import torch\n",
        "torch.__version__\n",
        "vector1= torch.rand(size=(3,4,5), dtype=torch.float64)\n",
        "vector2= torch.rand(size=(3,5,5), dtype=torch.float64)\n",
        "torch.matmul(vector1, vector2)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tZ3sIKPgzejx",
        "outputId": "5fac88f4-4d7e-4aca-c046-13c8a512bdcd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[[1.3087, 0.7132, 0.6957, 1.1423, 1.1824],\n",
              "         [1.4824, 0.8119, 0.4780, 1.4327, 0.9896],\n",
              "         [1.6104, 0.6933, 0.8547, 2.0084, 0.6549],\n",
              "         [1.4848, 0.8876, 0.5981, 1.3040, 1.0576]],\n",
              "\n",
              "        [[1.2947, 1.8769, 0.7934, 2.1384, 1.0168],\n",
              "         [1.3665, 1.5181, 1.2687, 1.5927, 0.9121],\n",
              "         [0.8691, 1.3688, 0.5277, 1.7011, 0.6323],\n",
              "         [0.5085, 0.9667, 0.2992, 0.9763, 0.3115]],\n",
              "\n",
              "        [[0.5444, 0.2357, 0.4053, 0.4628, 0.7034],\n",
              "         [1.6155, 0.9957, 1.5244, 0.6370, 1.9745],\n",
              "         [1.4264, 0.4420, 1.1426, 1.0552, 1.9779],\n",
              "         [0.6488, 0.1479, 0.4083, 0.8535, 0.8916]]], dtype=torch.float64)"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import torch\n",
        "torch.__version__\n",
        "# Since the linear layer starts with a random weights matrix, let's make it reproducible (more on this later)\n",
        "torch.manual_seed(42)\n",
        "# This uses matrix multiplication\n",
        "linear = torch.nn.Linear(in_features=2, # in_features = matches inner dimension of input\n",
        "                         out_features=6) # out_features = describes outer value\n",
        "x = tensor_A\n",
        "output = linear(x)\n",
        "print(f\"Input shape: {x.shape}\\n\")\n",
        "print(f\"Output:\\n{output}\\n\\nOutput shape: {output.shape}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 250
        },
        "id": "zG9nJkST5Uo3",
        "outputId": "ecb8bf08-65b1-4948-ed06-80d61ea60df1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-ee221f2553fc>\u001b[0m in \u001b[0;36m<cell line: 8>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m linear = torch.nn.Linear(in_features=2, # in_features = matches inner dimension of input \n\u001b[1;32m      7\u001b[0m                          out_features=6) # out_features = describes outer value \n\u001b[0;32m----> 8\u001b[0;31m \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtensor_A\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Input shape: {x.shape}\\n\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'tensor_A' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "torch.__version__\n",
        "torch.manual_seed(1234)\n",
        "torch.cuda.manual_seed(123)\n",
        "vector1= torch.rand(size=(7,7),dtype=torch.float32)\n",
        "vector2=torch.rand(size=(1,7),dtype=torch.float32)\n",
        "torch.mm(vector1, vector2.T)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0QbvwGiphL4D",
        "outputId": "da161f34-a06f-4714-b76d-0786dfe519e3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[1.5166],\n",
              "        [3.1874],\n",
              "        [2.5350],\n",
              "        [2.8343],\n",
              "        [2.6844],\n",
              "        [2.6483],\n",
              "        [2.4059]])"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "torch.__version__\n",
        "torch.manual_seed(0)\n",
        "\n",
        "if torch.cud.is_available():\n",
        "  num=torch.cuda.device_count()\n",
        "  print(\"the GPUs available are :: \",num)\n",
        "  vector1= torch.rand(size=(2,7)).to(device)\n",
        "  vector2= torch.rand(size= (3,7)).to(device)\n",
        "  torch.mm( vector1, vector2.T)\n",
        "else:\n",
        "  print(\"No GPUs available\")\n",
        "\n",
        "torch.backends.cudnn.deterministic = True\n",
        "torch.backends.cudnn.benchmark = False\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 375
        },
        "id": "vZmRRLiDVKIf",
        "outputId": "56be2098-f26a-4e7d-a113-13535ca3d66c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-8-d4b5827498ba>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__version__\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmanual_seed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcud\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_available\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    463\u001b[0m     \u001b[0;32mraise\u001b[0m  \u001b[0;31m# If __file__ is not None the cause is unknown, so just re-raise.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    464\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 465\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    466\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m'_'\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mendswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Base'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    467\u001b[0m         \u001b[0m__all__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name '_C' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "# Set the random seed for CPU\n",
        "torch.manual_seed(0)\n",
        "\n",
        "# Check if CUDA (GPU support) is available\n",
        "if torch.cuda.is_available():\n",
        "    # Set the random seed for GPU\n",
        "    torch.cuda.manual_seed(0)\n",
        "    torch.cuda.manual_seed_all(0)"
      ],
      "metadata": {
        "id": "Tnn3lpv4XGR5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import torch\n",
        "torch.__version__\n",
        "torch.manual_seed(1234)\n",
        "\n",
        "# Check for access to GPU\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "print(f\"Device: {device}\")\n",
        "\n",
        "# Create two random tensors on GPU\n",
        "tensor_A = torch.rand(size=(2,3)).to(device)\n",
        "tensor_B = torch.rand(size=(2,3)).to(device)\n",
        "tensor_A, tensor_B"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 375
        },
        "id": "di1FgHFJXuVe",
        "outputId": "0d6162fa-c71d-4f0b-a958-dc0d46bcd11f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-9-53a381076c8d>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__version__\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmanual_seed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1234\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# Check for access to GPU\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    463\u001b[0m     \u001b[0;32mraise\u001b[0m  \u001b[0;31m# If __file__ is not None the cause is unknown, so just re-raise.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    464\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 465\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    466\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m'_'\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mendswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Base'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    467\u001b[0m         \u001b[0m__all__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name '_C' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "torch.__version__\n",
        "tensor_A = torch.rand(size=(2,3)).to(device)\n",
        "tensor_B = torch.rand(size=(2,3)).to(device)\n",
        "tensor_A, tensor_B\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 250
        },
        "id": "-bmPK1q2acaA",
        "outputId": "0dcb1bf0-832c-44d8-f6d7-27cba785606e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-b6313269a35d>\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__version__\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mtensor_A\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrand\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mtensor_B\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrand\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mtensor_A\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor_B\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'device' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "\n",
        "if torch.cuda.is_available():\n",
        "\n",
        "    tensor1 = torch.rand(1, 7).to(torch.device(\"cuda\"))\n",
        "    tensor2 = torch.rand(6, 7).to(torch.device(\"cuda\"))\n",
        "\n",
        "\n",
        "    result = tensor1 + tensor2\n",
        "\n",
        "    # Move the result back to the CPU (if needed)\n",
        "    result = result.to(torch.device(\"cpu\"))\n",
        "\n",
        "    print(\"Tensor 1 on GPU:\")\n",
        "    print(tensor1)\n",
        "    print(\"Tensor 2 on GPU:\")\n",
        "    print(tensor2)\n",
        "    print(\"Result on CPU:\")\n",
        "    print(result)\n",
        "else:\n",
        "    print(\"GPU is not available.\")\n"
      ],
      "metadata": {
        "id": "3JpMIJhea9Nf",
        "outputId": "079709b4-d7ce-4fa4-9cc5-55d16811f319",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tensor 1 on GPU:\n",
            "tensor([[0.9952, 0.4957, 0.1500, 0.3557, 0.8829, 0.7015, 0.7016]],\n",
            "       device='cuda:0')\n",
            "Tensor 2 on GPU:\n",
            "tensor([[0.4982, 0.9412, 0.6679, 0.2497, 0.9673, 0.1014, 0.6686],\n",
            "        [0.1402, 0.2364, 0.5618, 0.6230, 0.6497, 0.2721, 0.6236],\n",
            "        [0.0516, 0.2377, 0.2953, 0.9223, 0.9556, 0.5098, 0.8716],\n",
            "        [0.3602, 0.8874, 0.6815, 0.2584, 0.2260, 0.0931, 0.1947],\n",
            "        [0.2427, 0.6690, 0.0238, 0.1292, 0.9941, 0.8839, 0.0831],\n",
            "        [0.1049, 0.1058, 0.6191, 0.6188, 0.2409, 0.9833, 0.1516]],\n",
            "       device='cuda:0')\n",
            "Result on CPU:\n",
            "tensor([[1.4934, 1.4369, 0.8179, 0.6054, 1.8502, 0.8029, 1.3702],\n",
            "        [1.1355, 0.7321, 0.7118, 0.9787, 1.5326, 0.9736, 1.3252],\n",
            "        [1.0468, 0.7334, 0.4453, 1.2780, 1.8385, 1.2114, 1.5732],\n",
            "        [1.3555, 1.3830, 0.8315, 0.6141, 1.1089, 0.7946, 0.8963],\n",
            "        [1.2380, 1.1647, 0.1739, 0.4849, 1.8770, 1.5855, 0.7847],\n",
            "        [1.1001, 0.6015, 0.7691, 0.9745, 1.1238, 1.6848, 0.8532]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "\n",
        "if torch.cuda.is_available():\n",
        "  device= torch.device(\"cuda\")\n",
        "  print(\"GPU is available and used\")\n",
        "\n",
        "else:\n",
        "  device= torch.device(\"cpu\")\n",
        "  print(\"CPU is available and used\")\n",
        "\n",
        "\n",
        "tensor1 = torch.rand(1, 7).to(torch.device(\"cuda\"))\n",
        "tensor2 = torch.rand(6, 7).to(torch.device(\"cuda\"))\n",
        "result= torch.mm( tensor1, tensor2.T)\n",
        "\n",
        "print(\"The matmul is :\", result)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nUsvAKbJclwi",
        "outputId": "6ec642bf-7745-4aea-8ba0-a1e877ef7e13"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GPU is available and used\n",
            "The matmul is : tensor([[2.2851, 2.3643, 1.6883, 1.5501, 1.5787, 1.7798]], device='cuda:0')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "\n",
        "if torch.cuda.is_available():\n",
        "  device= torch.device(\"cuda\")\n",
        "  print(\"GPU is available and used\")\n",
        "\n",
        "else:\n",
        "  device= torch.device(\"cpu\")\n",
        "  print(\"CPU is available and used\")\n",
        "\n",
        "\n",
        "tensor1 = torch.rand( size=(3,4), device=\"cuda\")\n",
        "tensor2 = torch.rand( size=(3,4), device=\"cuda\")\n",
        "result= torch.mm( tensor1, tensor2.T)\n",
        "\n",
        "print(\"The matmul is :\", result)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iwgqf1oHebA5",
        "outputId": "c51263b2-555c-4a0b-9c16-1b9a5b2ebc84"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GPU is available and used\n",
            "The matmul is : tensor([[1.4852, 1.2423, 1.5385],\n",
            "        [1.0881, 0.9462, 0.7647],\n",
            "        [0.9150, 0.7804, 0.5192]], device='cuda:0')\n"
          ]
        }
      ]
    }
  ]
}